"""
æ‰‹ã®éª¨æ ¼æ¤œå‡ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

MediaPipeã‚’ä½¿ç”¨ã—ã¦æ‰‹ã®21å€‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æ¤œå‡ºã—ã€
æŒ‡ã®è§’åº¦ã‚„å‹•ãã‚’è§£æã™ã‚‹
"""

import cv2
import numpy as np
import mediapipe as mp
from typing import Dict, List, Any, Optional, Tuple
import logging

logger = logging.getLogger(__name__)


class HandSkeletonDetector:
    """æ‰‹ã®éª¨æ ¼æ¤œå‡ºã‚¯ãƒ©ã‚¹"""
    
    FINGER_NAMES = ['thumb', 'index', 'middle', 'ring', 'pinky']
    
    FINGER_LANDMARK_IDS = {
        'thumb': [1, 2, 3, 4],
        'index': [5, 6, 7, 8],
        'middle': [9, 10, 11, 12],
        'ring': [13, 14, 15, 16],
        'pinky': [17, 18, 19, 20]
    }
    
    def __init__(self,
                 static_image_mode: bool = False,
                 max_num_hands: int = 2,
                 min_detection_confidence: float = 0.5,
                 min_tracking_confidence: float = 0.5,
                 flip_handedness: bool = False):
        """
        åˆæœŸåŒ– - ç´”ç²‹ãªMediaPipeå®Ÿè£…

        Args:
            static_image_mode: é™æ­¢ç”»ãƒ¢ãƒ¼ãƒ‰ï¼ˆTrueã§å„ãƒ•ãƒ¬ãƒ¼ãƒ å®Œå…¨æ¤œå‡ºã€ä¸¡æ‰‹æ¤œå‡ºã«æ¨å¥¨ï¼‰
            max_num_hands: æ¤œå‡ºã™ã‚‹æœ€å¤§æ‰‹æ•°
            min_detection_confidence: æ¤œå‡ºã®æœ€å°ä¿¡é ¼åº¦
            min_tracking_confidence: ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã®æœ€å°ä¿¡é ¼åº¦
            flip_handedness: æ‰‹ã®å·¦å³ã‚’åè»¢ã™ã‚‹ã‹ï¼ˆå¤–éƒ¨ã‚«ãƒ¡ãƒ©ã®å ´åˆTrueï¼‰
        """
        self.mp_hands = mp.solutions.hands
        self.mp_drawing = mp.solutions.drawing_utils
        self.flip_handedness = flip_handedness
        self.max_num_hands = max_num_hands

        # ç´”ç²‹ãªMediaPipe HandsåˆæœŸåŒ–
        self.hands = self.mp_hands.Hands(
            static_image_mode=static_image_mode,
            max_num_hands=max_num_hands,
            min_detection_confidence=min_detection_confidence,
            min_tracking_confidence=min_tracking_confidence
        )

        # ä¸¡æ‰‹æ¤œå‡ºç”¨ã®è¿½åŠ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆåˆ†å‰²å‡¦ç†ç”¨ï¼‰
        if max_num_hands == 2:
            self.hands_left = self.mp_hands.Hands(
                static_image_mode=True,
                max_num_hands=1,
                min_detection_confidence=min_detection_confidence * 0.8,  # ã‚„ã‚„ä½ã‚ã®é–¾å€¤
                min_tracking_confidence=min_tracking_confidence * 0.8
            )
            self.hands_right = self.mp_hands.Hands(
                static_image_mode=True,
                max_num_hands=1,
                min_detection_confidence=min_detection_confidence * 0.8,
                min_tracking_confidence=min_tracking_confidence * 0.8
            )
        else:
            self.hands_left = None
            self.hands_right = None

        logger.info("HandSkeletonDetector initialized with MediaPipe")
    
    def _normalize_landmarks(self, landmarks):
        """
        landmarksã‚’å¸¸ã«è¾æ›¸ã®ãƒªã‚¹ãƒˆã«æ­£è¦åŒ–

        Args:
            landmarks: numpyé…åˆ—ã€ãƒªã‚¹ãƒˆã€ã¾ãŸã¯è¾æ›¸ã®ãƒªã‚¹ãƒˆ

        Returns:
            æ­£è¦åŒ–ã•ã‚ŒãŸè¾æ›¸ã®ãƒªã‚¹ãƒˆ
        """
        if landmarks is None:
            return []

        # numpyé…åˆ—ã®å ´åˆ
        if isinstance(landmarks, np.ndarray):
            logger.debug(f"Converting numpy array landmarks with shape {landmarks.shape}")
            normalized = []
            for i in range(len(landmarks)):
                if len(landmarks[i]) >= 2:
                    normalized.append({
                        "x": float(landmarks[i][0]),
                        "y": float(landmarks[i][1]),
                        "z": float(landmarks[i][2]) if len(landmarks[i]) > 2 else 0.0,
                        "visibility": float(landmarks[i][3]) if len(landmarks[i]) > 3 else 1.0
                    })
            return normalized

        # ãƒªã‚¹ãƒˆã®å ´åˆ
        if isinstance(landmarks, list):
            if len(landmarks) == 0:
                return []

            # æœ€åˆã®è¦ç´ ã‚’ãƒã‚§ãƒƒã‚¯
            if isinstance(landmarks[0], dict):
                # æ—¢ã«æ­£ã—ã„å½¢å¼
                return landmarks
            elif isinstance(landmarks[0], (list, tuple, np.ndarray)):
                # ãƒªã‚¹ãƒˆã®ãƒªã‚¹ãƒˆã¾ãŸã¯ã‚¿ãƒ—ãƒ«ã®ãƒªã‚¹ãƒˆ
                logger.debug("Converting list of arrays/tuples to dict format")
                normalized = []
                for point in landmarks:
                    if len(point) >= 2:
                        normalized.append({
                            "x": float(point[0]),
                            "y": float(point[1]),
                            "z": float(point[2]) if len(point) > 2 else 0.0,
                            "visibility": float(point[3]) if len(point) > 3 else 1.0
                        })
                return normalized

        logger.warning(f"Unexpected landmarks format: {type(landmarks)}")
        return landmarks if isinstance(landmarks, list) else []

    def detect_from_frame(self, frame: np.ndarray) -> Dict[str, Any]:
        """
        ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰æ‰‹ã®éª¨æ ¼ã‚’æ¤œå‡º - ç´”ç²‹ãªMediaPipeå®Ÿè£…

        Args:
            frame: å…¥åŠ›ç”»åƒãƒ•ãƒ¬ãƒ¼ãƒ  (BGR)

        Returns:
            æ¤œå‡ºçµæœã®è¾æ›¸
        """
        # BGR to RGBå¤‰æ›ã®ã¿ï¼ˆå‰å‡¦ç†ãªã—ï¼‰
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # MediaPipeã§æ¤œå‡º
        results = self.hands.process(rgb_frame)

        detection_result = {
            "hands": [],
            "frame_shape": frame.shape[:2]
        }

        if results.multi_hand_landmarks:
            # Log detection info
            num_hands = len(results.multi_hand_landmarks)
            if num_hands > 1:
                logger.debug(f"Detected {num_hands} hands in frame")

            for hand_idx, (hand_landmarks, hand_info) in enumerate(
                zip(results.multi_hand_landmarks, results.multi_handedness)
            ):
                hand_data = self._process_hand_landmarks(
                    hand_landmarks,
                    hand_info,
                    frame.shape,
                    hand_idx
                )
                # landmarksã‚’æ­£è¦åŒ–
                if "landmarks" in hand_data:
                    hand_data["landmarks"] = self._normalize_landmarks(hand_data["landmarks"])
                detection_result["hands"].append(hand_data)

        # ä¸¡æ‰‹æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã§1ã¤ã—ã‹æ¤œå‡ºã•ã‚Œãªã‹ã£ãŸå ´åˆã€åˆ†å‰²å‡¦ç†ã‚’è©¦ã¿ã‚‹
        if self.max_num_hands == 2 and len(detection_result["hands"]) < 2 and self.hands_left and self.hands_right:
            detection_result["hands"] = self._detect_both_hands_split(frame, rgb_frame, detection_result["hands"])

        # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼ˆæœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿è©³ç´°å‡ºåŠ›ï¼‰
        if hasattr(self, '_debug_logged'):
            pass  # æ—¢ã«ãƒ­ã‚°å‡ºåŠ›æ¸ˆã¿
        else:
            self._debug_logged = True
            logger.info("=== SKELETON DETECTOR OUTPUT DEBUG ===")
            logger.info(f"Result type: {type(detection_result)}")
            logger.info(f"Number of hands: {len(detection_result.get('hands', []))}")
            if detection_result.get('hands'):
                first_hand = detection_result['hands'][0]
                logger.info(f"First hand keys: {list(first_hand.keys())}")
                if 'landmarks' in first_hand:
                    lm = first_hand['landmarks']
                    logger.info(f"Landmarks type: {type(lm)}")
                    if isinstance(lm, list) and len(lm) > 0:
                        logger.info(f"First landmark type: {type(lm[0])}")
                        if isinstance(lm[0], dict):
                            logger.info(f"First landmark keys: {list(lm[0].keys())}")

        # ğŸ”´ CRITICAL FIX: detectedã‚­ãƒ¼ã‚’è¿½åŠ ï¼ˆanalysis_service_v2ãŒä¾å­˜ï¼‰
        detection_result['detected'] = len(detection_result.get('hands', [])) > 0

        return detection_result


    def _detect_both_hands_split(self, frame: np.ndarray, rgb_frame: np.ndarray, initial_hands: List[Dict]) -> List[Dict]:
        """
        ç”»åƒã‚’å·¦å³ã«åˆ†å‰²ã—ã¦ä¸¡æ‰‹ã‚’æ¤œå‡ºã™ã‚‹æ”¹å–„ãƒ¡ã‚½ãƒƒãƒ‰

        Args:
            frame: å…ƒã®ãƒ•ãƒ¬ãƒ¼ãƒ  (BGR)
            rgb_frame: RGBå¤‰æ›æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            initial_hands: åˆå›æ¤œå‡ºã§è¦‹ã¤ã‹ã£ãŸæ‰‹

        Returns:
            æ”¹å–„ã•ã‚ŒãŸæ¤œå‡ºçµæœ
        """
        h, w = frame.shape[:2]
        mid_x = w // 2

        # å·¦åŠåˆ†ã¨å³åŠåˆ†ã‚’å‡¦ç†
        left_half = rgb_frame[:, :mid_x + 50]  # å°‘ã—ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—
        right_half = rgb_frame[:, mid_x - 50:]  # å°‘ã—ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—

        all_hands = []

        # å·¦åŠåˆ†ã‚’å‡¦ç†ï¼ˆé€šå¸¸å³æ‰‹ãŒæ˜ ã‚‹ï¼‰
        left_results = self.hands_left.process(left_half)
        if left_results.multi_hand_landmarks:
            for hand_landmarks, hand_info in zip(left_results.multi_hand_landmarks, left_results.multi_handedness):
                # åº§æ¨™ã‚’å…ƒç”»åƒã®åº§æ¨™ç³»ã«å¤‰æ›
                adjusted_landmarks = []
                for lm in hand_landmarks.landmark:
                    adjusted_landmarks.append({
                        "x": lm.x * left_half.shape[1] / w,  # æ­£è¦åŒ–åº§æ¨™ã«èª¿æ•´
                        "y": lm.y,
                        "z": lm.z,
                        "visibility": lm.visibility
                    })

                # MediaPipeã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
                class FakeLandmark:
                    def __init__(self, x, y, z, visibility):
                        self.x = x
                        self.y = y
                        self.z = z
                        self.visibility = visibility

                class FakeLandmarks:
                    def __init__(self, landmarks):
                        self.landmark = [FakeLandmark(lm["x"], lm["y"], lm["z"], lm["visibility"]) for lm in landmarks]

                fake_landmarks = FakeLandmarks(adjusted_landmarks)
                hand_data = self._process_hand_landmarks(fake_landmarks, hand_info, frame.shape, 0)
                all_hands.append(hand_data)

        # å³åŠåˆ†ã‚’å‡¦ç†ï¼ˆé€šå¸¸å·¦æ‰‹ãŒæ˜ ã‚‹ï¼‰
        right_results = self.hands_right.process(right_half)
        if right_results.multi_hand_landmarks:
            for hand_landmarks, hand_info in zip(right_results.multi_hand_landmarks, right_results.multi_handedness):
                # åº§æ¨™ã‚’å…ƒç”»åƒã®åº§æ¨™ç³»ã«å¤‰æ›
                adjusted_landmarks = []
                for lm in hand_landmarks.landmark:
                    adjusted_landmarks.append({
                        "x": (lm.x * right_half.shape[1] + (mid_x - 50)) / w,  # æ­£è¦åŒ–åº§æ¨™ã«èª¿æ•´
                        "y": lm.y,
                        "z": lm.z,
                        "visibility": lm.visibility
                    })

                class FakeLandmark:
                    def __init__(self, x, y, z, visibility):
                        self.x = x
                        self.y = y
                        self.z = z
                        self.visibility = visibility

                class FakeLandmarks:
                    def __init__(self, landmarks):
                        self.landmark = [FakeLandmark(lm["x"], lm["y"], lm["z"], lm["visibility"]) for lm in landmarks]

                fake_landmarks = FakeLandmarks(adjusted_landmarks)
                hand_data = self._process_hand_landmarks(fake_landmarks, hand_info, frame.shape, 1)
                all_hands.append(hand_data)

        # é‡è¤‡ã‚’é™¤å»ï¼ˆåŒã˜æ‰‹ãŒ2å›æ¤œå‡ºã•ã‚ŒãŸå ´åˆï¼‰
        if len(all_hands) > 1:
            # æ‰‹ã®ä½ç½®ãŒè¿‘ã™ãã‚‹å ´åˆã¯ä¿¡é ¼åº¦ã®é«˜ã„æ–¹ã‚’é¸æŠ
            hand1_center = all_hands[0]["palm_center"]
            hand2_center = all_hands[1]["palm_center"]
            distance = np.sqrt((hand1_center["x"] - hand2_center["x"])**2 +
                              (hand1_center["y"] - hand2_center["y"])**2)

            # è·é›¢ãŒè¿‘ã™ãã‚‹å ´åˆï¼ˆç”»åƒå¹…ã®10%æœªæº€ï¼‰
            if distance < w * 0.1:
                # ä¿¡é ¼åº¦ã®é«˜ã„æ–¹ã‚’æ®‹ã™
                if all_hands[0]["confidence"] > all_hands[1]["confidence"]:
                    all_hands = [all_hands[0]]
                else:
                    all_hands = [all_hands[1]]

        # åˆå›æ¤œå‡ºã®çµæœã¨çµ±åˆ
        if initial_hands:
            # æ—¢ã«æ¤œå‡ºã•ã‚Œã¦ã„ã‚‹æ‰‹ã¨é‡è¤‡ã—ãªã„ã‚‚ã®ã ã‘è¿½åŠ 
            for new_hand in all_hands:
                is_duplicate = False
                for existing_hand in initial_hands:
                    existing_center = existing_hand["palm_center"]
                    new_center = new_hand["palm_center"]
                    distance = np.sqrt((existing_center["x"] - new_center["x"])**2 +
                                      (existing_center["y"] - new_center["y"])**2)
                    if distance < w * 0.1:  # é‡è¤‡åˆ¤å®š
                        is_duplicate = True
                        break

                if not is_duplicate and len(initial_hands) < 2:
                    initial_hands.append(new_hand)

            return initial_hands
        else:
            return all_hands[:2]  # æœ€å¤§2ã¤ã¾ã§
    
    def _process_hand_landmarks(self,
                                hand_landmarks,
                                hand_info,
                                frame_shape: Tuple[int, int, int],
                                hand_idx: int = 0) -> Dict[str, Any]:
        """
        æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’å‡¦ç†
        
        Args:
            hand_landmarks: MediaPipeã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
            hand_info: æ‰‹ã®æƒ…å ±ï¼ˆå·¦å³ãªã©ï¼‰
            frame_shape: ãƒ•ãƒ¬ãƒ¼ãƒ ã®å½¢çŠ¶
        
        Returns:
            å‡¦ç†ã•ã‚ŒãŸæ‰‹ã®ãƒ‡ãƒ¼ã‚¿
        """
        height, width = frame_shape[:2]
        
        landmarks_list = []
        for landmark in hand_landmarks.landmark:
            landmarks_list.append({
                "x": landmark.x * width,
                "y": landmark.y * height,
                "z": landmark.z,
                "visibility": landmark.visibility
            })
        
        finger_angles = self._calculate_finger_angles(landmarks_list)
        
        palm_center = self._calculate_palm_center(landmarks_list)
        
        hand_openness = self._calculate_hand_openness(finger_angles)

        # Get the raw handedness from MediaPipe
        raw_label = hand_info.classification[0].label

        # Apply flip if needed (for external cameras)
        if self.flip_handedness:
            # External camera: flip the handedness
            final_label = "Left" if raw_label == "Right" else "Right"
        else:
            # Internal camera or no flip: use as-is
            final_label = raw_label

        # Add hand_id for tracking (like in reference code)
        hand_id = hand_idx

        return {
            "hand_id": hand_id,  # Add hand_id like reference code
            "label": final_label,
            "handedness": final_label,
            "confidence": hand_info.classification[0].score,
            "landmarks": landmarks_list,
            "finger_angles": finger_angles,
            "palm_center": palm_center,
            "hand_openness": hand_openness,
            "bbox": self._calculate_bbox(landmarks_list)
        }
    
    def _calculate_finger_angles(self, landmarks: List[Dict[str, float]]) -> Dict[str, float]:
        """
        å„æŒ‡ã®æ›²ãŒã‚Šè§’åº¦ã‚’è¨ˆç®—
        
        Args:
            landmarks: ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®ãƒªã‚¹ãƒˆ
        
        Returns:
            å„æŒ‡ã®è§’åº¦ï¼ˆåº¦æ•°ï¼‰
        """
        angles = {}
        
        for finger_name in self.FINGER_NAMES:
            landmark_ids = self.FINGER_LANDMARK_IDS[finger_name]
            
            if finger_name == 'thumb':
                p1 = np.array([landmarks[0]["x"], landmarks[0]["y"]])
                p2 = np.array([landmarks[landmark_ids[1]]["x"], 
                             landmarks[landmark_ids[1]]["y"]])
                p3 = np.array([landmarks[landmark_ids[2]]["x"], 
                             landmarks[landmark_ids[2]]["y"]])
            else:
                p1 = np.array([landmarks[landmark_ids[0]]["x"], 
                             landmarks[landmark_ids[0]]["y"]])
                p2 = np.array([landmarks[landmark_ids[1]]["x"], 
                             landmarks[landmark_ids[1]]["y"]])
                p3 = np.array([landmarks[landmark_ids[2]]["x"], 
                             landmarks[landmark_ids[2]]["y"]])
            
            angle = self._calculate_angle(p1, p2, p3)
            angles[finger_name] = angle
        
        return angles
    
    def _calculate_angle(self, p1: np.ndarray, p2: np.ndarray, p3: np.ndarray) -> float:
        """
        3ç‚¹é–“ã®è§’åº¦ã‚’è¨ˆç®—
        
        Args:
            p1, p2, p3: 3ã¤ã®ç‚¹ã®åº§æ¨™
        
        Returns:
            è§’åº¦ï¼ˆåº¦æ•°ï¼‰
        """
        v1 = p1 - p2
        v2 = p3 - p2
        
        cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-6)
        
        cos_angle = np.clip(cos_angle, -1.0, 1.0)
        
        angle = np.degrees(np.arccos(cos_angle))
        
        return float(angle)
    
    def _calculate_palm_center(self, landmarks: List[Dict[str, float]]) -> Dict[str, float]:
        """
        æ‰‹ã®ã²ã‚‰ã®ä¸­å¿ƒåº§æ¨™ã‚’è¨ˆç®—
        
        Args:
            landmarks: ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®ãƒªã‚¹ãƒˆ
        
        Returns:
            ä¸­å¿ƒåº§æ¨™
        """
        palm_landmarks = [0, 1, 5, 9, 13, 17]
        
        x_coords = [landmarks[i]["x"] for i in palm_landmarks]
        y_coords = [landmarks[i]["y"] for i in palm_landmarks]
        
        return {
            "x": float(np.mean(x_coords)),
            "y": float(np.mean(y_coords))
        }
    
    def _calculate_hand_openness(self, finger_angles: Dict[str, float]) -> float:
        """
        æ‰‹ã®é–‹ãå…·åˆã‚’è¨ˆç®—ï¼ˆ0-100%ï¼‰
        
        Args:
            finger_angles: å„æŒ‡ã®è§’åº¦
        
        Returns:
            é–‹ãå…·åˆã®ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸
        """
        max_angle = 180.0
        
        total_openness = 0
        for finger, angle in finger_angles.items():
            openness = (max_angle - angle) / max_angle
            total_openness += openness
        
        average_openness = (total_openness / len(finger_angles)) * 100
        
        return float(np.clip(average_openness, 0, 100))
    
    def _calculate_bbox(self, landmarks: List[Dict[str, float]]) -> Dict[str, float]:
        """
        æ‰‹ã®å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã‚’è¨ˆç®—
        
        Args:
            landmarks: ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®ãƒªã‚¹ãƒˆ
        
        Returns:
            å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹åº§æ¨™
        """
        x_coords = [lm["x"] for lm in landmarks]
        y_coords = [lm["y"] for lm in landmarks]
        
        margin = 20
        
        return {
            "x_min": float(max(0, min(x_coords) - margin)),
            "y_min": float(max(0, min(y_coords) - margin)),
            "x_max": float(max(x_coords) + margin),
            "y_max": float(max(y_coords) + margin)
        }
    
    def draw_landmarks(self, frame: np.ndarray, detection_result: Dict[str, Any]) -> np.ndarray:
        """
        æ¤œå‡ºçµæœã‚’ç”»åƒã«æç”»
        
        Args:
            frame: å…¥åŠ›ç”»åƒ
            detection_result: æ¤œå‡ºçµæœ
        
        Returns:
            æç”»ã•ã‚ŒãŸç”»åƒ
        """
        annotated_frame = frame.copy()
        
        for hand_data in detection_result.get("hands", []):
            landmarks = hand_data["landmarks"]
            
            for i, landmark in enumerate(landmarks):
                x = int(landmark["x"])
                y = int(landmark["y"])
                cv2.circle(annotated_frame, (x, y), 5, (0, 255, 0), -1)
                
                if i > 0:
                    if i in [1, 5, 9, 13, 17]:
                        prev_idx = 0
                    elif i in [2, 6, 10, 14, 18]:
                        prev_idx = i - 1
                    elif i in [3, 7, 11, 15, 19]:
                        prev_idx = i - 1
                    elif i in [4, 8, 12, 16, 20]:
                        prev_idx = i - 1
                    else:
                        prev_idx = i - 1
                    
                    prev_x = int(landmarks[prev_idx]["x"])
                    prev_y = int(landmarks[prev_idx]["y"])
                    cv2.line(annotated_frame, (prev_x, prev_y), (x, y), (0, 255, 0), 2)
            
            label = f"{hand_data['label']} ({hand_data['confidence']:.2f})"
            bbox = hand_data["bbox"]
            cv2.putText(annotated_frame, label,
                       (int(bbox["x_min"]), int(bbox["y_min"]) - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            
            cv2.rectangle(annotated_frame,
                         (int(bbox["x_min"]), int(bbox["y_min"])),
                         (int(bbox["x_max"]), int(bbox["y_max"])),
                         (0, 255, 0), 2)
        
        return annotated_frame

    def detect_batch(self, frames: List[np.ndarray]) -> List[Dict[str, Any]]:
        """
        è¤‡æ•°ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¯¾ã—ã¦ãƒãƒƒãƒæ¤œå‡ºã‚’å®Ÿè¡Œ

        Args:
            frames: ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒªã‚¹ãƒˆ

        Returns:
            æ¤œå‡ºçµæœã®ãƒªã‚¹ãƒˆ
        """
        results = []
        for idx, frame in enumerate(frames):
            result = self.detect_from_frame(frame)
            result['frame_index'] = idx  # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¿½åŠ 
            results.append(result)
        return results

    def __del__(self):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if hasattr(self, 'hands'):
            self.hands.close()
        if hasattr(self, 'hands_left') and self.hands_left:
            self.hands_left.close()
        if hasattr(self, 'hands_right') and self.hands_right:
            self.hands_right.close()