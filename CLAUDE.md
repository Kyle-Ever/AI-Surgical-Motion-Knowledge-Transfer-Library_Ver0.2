# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Language Preference
**æ—¥æœ¬èªã§å¿œç­”ã—ã¦ãã ã•ã„** - Please respond in Japanese unless explicitly requested otherwise.

## Critical Environment Requirements

### Python 3.11 MANDATORY
**MUST use Python 3.11** - Python 3.13 breaks MediaPipe/OpenCV compatibility
- Virtual environment: `backend\venv311\`
- Always use: `./venv311/Scripts/python.exe` for backend operations
- Check version: `./venv311/Scripts/python.exe --version` should show 3.11.x

### CORS Configuration (Development)
**Upload feature requires these settings:**
- Backend: `allow_origins=["*"]` in `backend/app/main.py`
- Frontend: `.env.local` with `NEXT_PUBLIC_API_URL=http://localhost:8000/api/v1`
- Backend `.env`: `BACKEND_CORS_ORIGINS=["http://localhost:3000","http://localhost:3001","http://localhost:8000"]`

### Environment Variables
**Backend (.env)**
```
DATABASE_URL=sqlite:///./aimotion.db
UPLOAD_DIR=data/uploads
MAX_UPLOAD_SIZE=2147483648  # 2GB in bytes
BACKEND_CORS_ORIGINS=["http://localhost:3000","http://localhost:3001","http://localhost:8000"]
```

**Frontend (.env.local)**
```
NEXT_PUBLIC_API_URL=http://localhost:8000/api/v1
NEXT_PUBLIC_WS_URL=ws://localhost:8000
```

## Commands

### Quick Start
```bash
# Both servers (recommended)
start_both.bat

# Backend only
cd backend && ./venv311/Scripts/python.exe -m uvicorn app.main:app --reload --port 8000

# Frontend only
cd frontend && npm install && npm run dev
```

### Dependencies Installation
```bash
# Backend dependencies
cd backend
./venv311/Scripts/python.exe -m pip install -r requirements.txt

# Frontend dependencies
cd frontend
npm install
```

### Testing
```bash
# Frontend E2E (Playwright)
cd frontend
npm run test              # Headless
npm run test:ui           # Interactive UI
npm run test:headed       # Browser visible
npm run test:report       # View test report
npx playwright test upload.spec.ts  # Single file
npx playwright test --grep "upload"  # Pattern matching

# Frontend type check & lint
cd frontend
npm run lint              # ESLint check
npx tsc --noEmit         # TypeScript check

# Backend API tests
cd backend
./venv311/Scripts/python.exe test_api.py
./venv311/Scripts/python.exe test_mediapipe_integration.py
./venv311/Scripts/python.exe test_analysis_processing.py
./venv311/Scripts/python.exe tests/test_integration.py

# Backend database check
./venv311/Scripts/python.exe check_db.py
```

### Development Commands
```bash
# Frontend
npm run build             # Production build
npm run lint              # ESLint v9
npm run test:debug        # Debug Playwright tests

# Backend database
cd backend
sqlite3 aimotion.db ".tables"  # Direct SQL access
sqlite3 aimotion.db ".schema videos"  # Table schema
```

## High-Level Architecture

### Processing Pipeline
1. **Upload**: Video â†’ `backend/data/uploads/` (2GB max, .mp4 only)
2. **Analysis**: Frame extraction â†’ AI detection â†’ Score calculation
3. **Detection Types**:
   - `external` videos: MediaPipe skeleton detection (hand tracking)
   - `internal` videos: YOLOv8 instrument detection + SAM tracker
4. **Real-time Updates**: WebSocket progress at `/ws/analysis/{analysis_id}`

### Key API Endpoints
- `POST /api/v1/videos/upload` - Upload video (2GB limit)
- `POST /api/v1/analysis/{video_id}/analyze` - Start analysis
- `GET /api/v1/analysis/{analysis_id}/status` - Check progress
- `GET /api/v1/videos` - List all videos with pagination
- `GET /api/v1/analysis/{analysis_id}` - Get analysis results
- `POST /api/v1/scoring/compare` - Compare analysis with reference
- `GET /api/v1/library/references` - Get reference videos
- `POST /api/v1/instrument-tracking/{video_id}/track` - Start instrument tracking
- `WS /ws/analysis/{analysis_id}` - Real-time progress

### Core Services Architecture
- **AnalysisService** (`backend/app/services/analysis_service.py`): Orchestrates entire processing pipeline with step-based progress tracking
- **ScoringService** (`backend/app/services/scoring_service.py`): Calculates motion metrics and comparison scores
- **InstrumentTrackingService** (`backend/app/services/instrument_tracking_service.py`): Handles surgical instrument detection and tracking
- **MetricsCalculator** (`backend/app/services/metrics_calculator.py`): Computes motion metrics from tracking data
- **WebSocket Manager** (`backend/app/core/websocket.py`): Manages real-time client connections
- **AI Processors** (`backend/app/ai_engine/processors/`): Modular detection components
  - `skeleton_detector.py`: MediaPipe hand/body tracking
  - `sam_tracker.py`: Segment Anything Model for instruments
  - `hybrid_hand_detector.py`: Combined detection approach
  - `glove_hand_detector.py`: White surgical glove detection
  - `enhanced_hand_detector.py`: Improved detection accuracy
- **Frontend State**: Zustand for global state, custom hooks for WebSocket connections

### Database Schema
SQLite at `backend/aimotion.db` with SQLAlchemy ORM:
- `videos`: Video metadata and upload info
- `analyses`: Analysis sessions and results
- `reference_videos`: Gold standard references
- `comparisons`: Score comparisons between videos

## Implementation Patterns

### Async Processing (Backend)
```python
# MediaPipe blocks, use executor:
loop = asyncio.get_event_loop()
result = await loop.run_in_executor(None, process_with_mediapipe, frames)
```

### WebSocket Updates
```python
from app.core.websocket import manager
await manager.send_update(analysis_id, {
    "type": "progress",
    "step": "skeleton_detection",
    "progress": 50
})
```

### Frontend State Management (Zustand)
```typescript
// stores/useVideoStore.ts
import { create } from 'zustand'

const useVideoStore = create((set) => ({
  videos: [],
  setVideos: (videos) => set({ videos }),
  addVideo: (video) => set((state) => ({
    videos: [...state.videos, video]
  }))
}))
```

### Custom Hooks Pattern
```typescript
// hooks/useWebSocket.ts
export function useWebSocket(analysisId: string) {
  const [progress, setProgress] = useState(0)

  useEffect(() => {
    const ws = new WebSocket(`ws://localhost:8000/ws/analysis/${analysisId}`)
    ws.onmessage = (e) => setProgress(JSON.parse(e.data).progress)
    return () => ws.close()
  }, [analysisId])

  return { progress }
}
```

## Key Constraints
- **Python Version**: Python 3.11.9 ONLY (3.13 breaks MediaPipe/OpenCV)
- **Dependencies**: `numpy<2`, `ultralytics==8.0.200`, `mediapipe>=0.10.0` (fixed versions)
- **File Limits**: 2GB uploads, .mp4 only
- **Ports**: Backend 8000, Frontend 3000
- **Frontend**: Next.js 15.5.2 with Turbopack, TypeScript, Tailwind CSS v4
- **State Management**: Zustand v5.0.8 for global state
- **Charts**: Chart.js v4.5.0, react-chartjs-2 v5.3.0, recharts v3.2.1
- **3D Rendering**: Three.js with @react-three/fiber for 3D visualizations
- **Testing**: Playwright v1.55.0 expects Japanese UI text
- **Batch Files**: Use Windows batch files (`start_both.bat`, etc.) for consistent environment

## Development Process
For non-trivial changes, follow `docs/Rules/`:
1. **PRD Creation** (`01_prd_generation_rules.md`)
2. **Task Decomposition** (`02_task_generation_rules.md`) - 15-90 min tasks
3. **Execution** (`03_task_execution_rules.md`) - One task at a time

## ğŸš¨ Troubleshooting Guide

### âš ï¸ **ã‚³ãƒ¼ãƒ‰å¤‰æ›´ãŒåæ˜ ã•ã‚Œãªã„å ´åˆ**
**åŸå› **: å¤ã„ãƒ—ãƒ­ã‚»ã‚¹ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã„ã‚‹

**è¨ºæ–­æ‰‹é †**:
1. ãƒ–ãƒ©ã‚¦ã‚¶ã§å¤‰æ›´ãŒåæ˜ ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
2. é–‹ç™ºè€…ãƒ„ãƒ¼ãƒ«ã®Consoleã§ã‚¨ãƒ©ãƒ¼ç¢ºèª
3. åˆ¥ã®ãƒãƒ¼ãƒˆã§èµ·å‹•ã—ã¦æ¯”è¼ƒ
   ```bash
   # ãƒãƒ¼ãƒˆ3000ã§å•é¡ŒãŒã‚ã‚‹å ´åˆã€3002ã§è©¦ã™
   npm run dev -- --port 3002
   ```

**è§£æ±ºæ–¹æ³•**:
```bash
# 1. ç¾åœ¨ã®ãƒãƒ¼ãƒˆä½¿ç”¨çŠ¶æ³ã‚’ç¢ºèª
netstat -ano | findstr :3000

# 2. å¤ã„ãƒ—ãƒ­ã‚»ã‚¹ã‚’å¼·åˆ¶çµ‚äº†
taskkill /PID <process_id> /F
# ã¾ãŸã¯å…¨Node.jsãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†
taskkill /F /IM node.exe

# 3. .nextã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ï¼ˆå¿…è¦ãªå ´åˆï¼‰
cd frontend
rmdir /s /q .next
npm run dev

# 4. ãƒ–ãƒ©ã‚¦ã‚¶ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚ã‚¯ãƒªã‚¢
# Ctrl+Shift+R ã§ãƒãƒ¼ãƒ‰ãƒªãƒ­ãƒ¼ãƒ‰
```

**äºˆé˜²ç­–**:
- å¤§ããªå¤‰æ›´ï¼ˆHTMLè¦ç´ ã®å¤‰æ›´ç­‰ï¼‰å¾Œã¯å¿…ãšã‚µãƒ¼ãƒãƒ¼å†èµ·å‹•
- é•·æ™‚é–“å®Ÿè¡Œã—ã¦ã„ã‚‹é–‹ç™ºã‚µãƒ¼ãƒãƒ¼ã¯å®šæœŸçš„ã«å†èµ·å‹•
- `git diff`ã§å¤‰æ›´å†…å®¹ã‚’ç¢ºèªã—ã¦ã‹ã‚‰å®Ÿè¡Œ

### ğŸ”´ **Runtime TypeErrors (null/undefinedå‚ç…§)**
**ç—‡çŠ¶**: `Cannot read properties of null (reading 'xxx')`

**ä¸»ãªç™ºç”Ÿç®‡æ‰€**:
- ScoreComparison: `result?.efficiency_score`
- FeedbackPanel: `result?.feedback`
- MotionAnalysisPanel: `analysisData?.skeleton_data`

**è§£æ±ºæ–¹æ³•**:
```typescript
// âŒ Bad - nullå‚ç…§ã‚¨ãƒ©ãƒ¼ã®å¯èƒ½æ€§
{result.efficiency_score}

// âœ… Good - Optional chaining + fallback
{result?.efficiency_score ?? '--'}

// âœ… Good - ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
const data = result?.metrics || mockMetrics
```

### ğŸŸ¡ **Enum Validation Errors**
**ç—‡çŠ¶**: `422 Unprocessable Entity` - Pydantic validation error

**åŸå› **: Backend model ã¨ schema ã® enum å®šç¾©ä¸ä¸€è‡´

**è§£æ±ºæ–¹æ³•**:
```python
# backend/app/schemas/video.py
class VideoType(str, Enum):
    internal = "internal"
    external = "external"  # å¾Œæ–¹äº’æ›æ€§
    external_no_instruments = "external_no_instruments"
    external_with_instruments = "external_with_instruments"
```

### ğŸ”µ **Module Not Found Errors**
**ç—‡çŠ¶**: `Module not found: Can't resolve 'tailwind-merge'`

**è§£æ±ºæ–¹æ³•**:
```bash
# ä¾å­˜é–¢ä¿‚ã‚’å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
cd frontend
npm install tailwind-merge
# ã¾ãŸã¯å…¨ä½“çš„ã«å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
rm -rf node_modules package-lock.json
npm install
```

### ğŸŸ¢ **WebSocket Connection Issues**
**ç—‡çŠ¶**: è§£æé€²æ—ãŒæ›´æ–°ã•ã‚Œãªã„

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**:
1. Backendèµ·å‹•ç¢ºèª: `http://localhost:8000/docs`
2. WebSocket URLç¢ºèª: `ws://localhost:8000/ws/analysis/{id}`
3. CORSè¨­å®šç¢ºèª: Backend `allow_origins=["*"]`
4. ãƒ–ãƒ©ã‚¦ã‚¶ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§WebSocketæ¥ç¶šç¢ºèª

### ğŸŸ  **File Upload Issues**
**ç—‡çŠ¶**: ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠãƒœã‚¿ãƒ³ãŒåå¿œã—ãªã„

**æ ¹æœ¬åŸå› **: Buttonè¦ç´ ãŒspan/divã«å¤‰æ›´ã•ã‚Œã¦ã„ã‚‹

**ç¢ºèªæ–¹æ³•**:
```bash
# è¦ç´ ã®ç¢ºèª
cd frontend
grep -n "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ" app/upload/page.tsx
```

**ä¿®æ­£**:
```tsx
// âŒ Bad - ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆãŒå‹•ä½œã—ãªã„
<span className="...">ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ</span>

// âœ… Good - æ­£ã—ã„buttonè¦ç´ 
<button
  type="button"
  onClick={() => open()}
  className="..."
>
  ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
</button>
```

### ğŸ”´ **Python Version Issues**
**ç—‡çŠ¶**: `ModuleNotFoundError: No module named 'mediapipe'`

**åŸå› **: Python 3.13ã§MediaPipeãŒå‹•ä½œã—ãªã„

**è§£æ±ºæ–¹æ³•**:
```bash
# å¿…ãšPython 3.11ã‚’ä½¿ç”¨
cd backend
./venv311/Scripts/python.exe --version  # 3.11.xç¢ºèª
./venv311/Scripts/python.exe -m pip install mediapipe
```

### Common Error Patterns & Quick Fixes

| ã‚¨ãƒ©ãƒ¼ | åŸå›  | è§£æ±ºæ–¹æ³• |
|--------|------|----------|
| CORS error | Backendè¨­å®šä¸å‚™ | `allow_origins=["*"]` è¨­å®š |
| Import errors | Python version | `./venv311/Scripts/python.exe` ä½¿ç”¨ |
| WebSocket disconnects | ã‚µãƒ¼ãƒãƒ¼æœªèµ·å‹• | `start_both.bat` å®Ÿè¡Œ |
| Upload failures | ã‚µã‚¤ã‚ºåˆ¶é™ | 2GBä»¥ä¸‹ã®.mp4ã®ã¿ |
| MediaPipe errors | Python 3.13ä½¿ç”¨ | Python 3.11ã«å¤‰æ›´ |
| Detection failures | video_typeèª¤ã‚Š | external/internalç¢ºèª |
| Frontend 404 | ENVè¨­å®šæ¼ã‚Œ | `.env.local` ç¢ºèª |
| Async blocks | åŒæœŸå‡¦ç† | `run_in_executor` ä½¿ç”¨ |

## âš ï¸ Critical UI Elements - DO NOT MODIFY
**These elements must remain as specific HTML tags for functionality:**
- Upload button: Must be `<button>`, not `<span>` or `<div>`
- Form inputs: Must be `<input>`, not styled divs
- Dropzone: Requires proper `useDropzone` hook configuration
- File input: Must have `type="file"` attribute
- Video player: Must be `<video>` element
- Canvas overlays: Must maintain proper z-index

**Testing critical UI elements:**
```bash
# Run regression tests after any UI changes
cd frontend
npx playwright test button-regression.spec.ts
npx playwright test upload.spec.ts
```

## ğŸ”§ Debug Commands

```bash
# ãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª
netstat -ano | findstr :3000
netstat -ano | findstr :8000
tasklist | findstr node
tasklist | findstr python

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
cd frontend && rmdir /s /q .next
cd backend && del /s /q __pycache__

# ãƒ­ã‚°ç¢ºèª
cd backend && type uvicorn.log
cd frontend && npm run dev 2>&1 | tee dev.log

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç¢ºèª
cd backend
sqlite3 aimotion.db "SELECT * FROM videos;"
sqlite3 aimotion.db "SELECT * FROM analyses WHERE status='failed';"
sqlite3 aimotion.db "SELECT * FROM reference_videos;"
sqlite3 aimotion.db "SELECT * FROM comparisons;"

# APIå¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
curl http://localhost:8000/api/v1/health
curl http://localhost:8000/docs
```

## Project-Specific Notes

### AI Surgical Motion Knowledge Transfer Library
This system analyzes surgical procedure videos to:
1. Track hand and instrument movements
2. Calculate motion efficiency metrics
3. Compare performance against reference videos
4. Provide feedback for skill improvement

### Video Processing Modes
- **external/external_no_instruments**: Hand-only tracking using MediaPipe
- **external_with_instruments/internal**: Instrument tracking using YOLOv8 + SAM
- Detection accuracy varies with surgical glove color (white gloves require enhanced detection)

### Model Files Required
- `backend/yolov8n.pt`: YOLOv8 nano model for instrument detection
- `backend/yolov8n-pose.pt`: YOLOv8 pose model
- `backend/sam_b.pt`: Segment Anything Model (base)